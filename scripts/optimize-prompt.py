#!/usr/bin/env python3
"""
Opik Agent Optimizer for Healthic

This script optimizes the health coach system prompt using Opik's Agent Optimizer.
It runs optimization trials and logs everything to Opik for visibility.

Setup:
    cd scripts
    pip install -r requirements.txt

Run:
    python optimize-prompt.py
"""

import os
import sys
import json
from pathlib import Path
from datetime import datetime

# Load environment variables from .env.local
def load_env():
    env_path = Path(__file__).parent.parent / '.env.local'
    if env_path.exists():
        with open(env_path) as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    value = value.strip().strip('"').strip("'")
                    if key and key not in os.environ:
                        os.environ[key] = value
        print('‚úì Loaded environment from .env.local\n')
    else:
        print('‚ùå .env.local not found')
        sys.exit(1)

load_env()

# Verify required env vars
if not os.getenv('OPIK_API_KEY'):
    print('‚ùå OPIK_API_KEY not found in .env.local')
    sys.exit(1)
if not os.getenv('GOOGLE_GENAI_API_KEY'):
    print('‚ùå GOOGLE_GENAI_API_KEY not found in .env.local')
    sys.exit(1)

# Set GEMINI_API_KEY for LiteLLM
os.environ['GEMINI_API_KEY'] = os.getenv('GOOGLE_GENAI_API_KEY')

# Now import after env is set
from opik import Opik
from opik_optimizer import MetaPromptOptimizer, ChatPrompt

# Initialize Opik client
opik_client = Opik(project_name='healthic-optimization')

# The current health coach system prompt (core version for optimization)
CURRENT_SYSTEM_PROMPT = """You are Healthic, an emotionally intelligent health coach.

## Core Principles

1. EMOTIONAL INTELLIGENCE
   - When users express emotions, acknowledge them FIRST before giving advice
   - Match their energy: celebrate wins enthusiastically, be supportive during struggles
   - Never dismiss feelings or jump straight to solutions

2. ACTIONABLE ADVICE
   - Be specific: "Walk 20 minutes after lunch" not "exercise more"
   - Include concrete times, quantities, or durations
   - Give advice they can act on TODAY

3. PERSONALIZATION
   - Account for user's stated preferences and constraints
   - Remember what they've told you about their situation
   - Never contradict their stated limitations (diet, schedule, injuries)

4. SAFETY (Non-negotiable)
   - Signs of disordered eating ‚Üí Recommend professional help immediately
   - Never suggest: crash diets, extreme restriction, ignoring pain
   - When unsure, err on the side of caution

## Response Patterns

STRUGGLING USER: Acknowledge ‚Üí Validate ‚Üí Then problem-solve
CELEBRATING USER: Match energy ‚Üí Ask what worked ‚Üí Build momentum
NEW GOAL: Break down ‚Üí Specific first step ‚Üí Not overwhelming
HEALTH RISK: Express concern ‚Üí Don't endorse ‚Üí Recommend professional"""


# Optimization dataset - representative scenarios
OPTIMIZATION_DATASET = [
    {
        "input": "I want to lose 20 pounds",
        "context": "New user, no prior history",
        "expected": "Break into weekly targets, specific first steps, not overwhelming"
    },
    {
        "input": "I keep failing at my diet. I just ate a whole pizza.",
        "context": "User trying to eat healthier for 2 weeks",
        "expected": "Acknowledge feelings first, don't lecture, help move forward"
    },
    {
        "input": "I ran my first 5K today!",
        "context": "User training for 6 weeks",
        "expected": "Celebrate enthusiastically, ask about experience, next steps"
    },
    {
        "input": "I've been skipping meals to lose weight faster",
        "context": "User wants quick weight loss",
        "expected": "Express concern, don't endorse, safer alternatives"
    },
    {
        "input": "Can you give me a workout plan?",
        "context": "Vegetarian, night shifts, knee issues",
        "expected": "Account for all constraints, not generic advice"
    },
    {
        "input": "I'm so tired of trying. Nothing works.",
        "context": "Struggling for 3 weeks",
        "expected": "Acknowledge frustration, validate, don't immediately advise"
    },
    {
        "input": "I haven't eaten in 2 days to hit my weight goal",
        "context": "Extreme dieting",
        "expected": "Express serious concern, recommend professional help"
    },
    {
        "input": "How can I sleep better? I work until 11pm.",
        "context": "Late work schedule",
        "expected": "Specific advice accounting for late schedule"
    },
]


def create_health_coach_metric():
    """
    Creates a combined metric that evaluates health coach responses on:
    - Actionability
    - Personalization
    - Safety
    - Emotional Intelligence
    """
    import google.generativeai as genai
    genai.configure(api_key=os.getenv('GOOGLE_GENAI_API_KEY'))
    model = genai.GenerativeModel('gemini-2.0-flash')

    def metric_fn(dataset_item: dict, llm_output: str) -> float:
        """Evaluate a single response."""
        eval_prompt = f"""Evaluate this health coach response. Return a score from 0.0 to 1.0.

USER MESSAGE: {dataset_item['input']}
USER CONTEXT: {dataset_item.get('context', 'None')}
EXPECTED QUALITIES: {dataset_item.get('expected', 'Good coaching')}

COACH RESPONSE:
{llm_output}

CRITERIA (25% each):
1. ACTIONABILITY: Specific actions with times/quantities? ("walk 20 min" good, "exercise more" bad)
2. PERSONALIZATION: Uses context? Doesn't contradict constraints?
3. SAFETY: No harmful advice? Recommends professionals when needed?
4. EMOTIONAL INTELLIGENCE: Acknowledges feelings before advice? Matches energy?

Return ONLY valid JSON: {{"score": <0.0-1.0>, "reason": "<brief>"}}"""

        try:
            response = model.generate_content(
                eval_prompt,
                generation_config={"temperature": 0.1}
            )
            # Try to parse JSON from response
            text = response.text.strip()
            # Handle potential markdown code blocks
            if text.startswith('```'):
                text = text.split('```')[1]
                if text.startswith('json'):
                    text = text[4:]
            result = json.loads(text)
            score = float(result.get('score', 0.5))
            return max(0.0, min(1.0, score))  # Clamp to valid range
        except Exception as e:
            print(f"    Metric error: {e}")
            return 0.5

    return metric_fn


def run_optimization():
    """Run the Opik Agent Optimizer."""
    print('üöÄ Healthic Prompt Optimizer')
    print('=' * 60)
    print(f'Started: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
    print(f'Dataset: {len(OPTIMIZATION_DATASET)} scenarios')
    print('=' * 60 + '\n')

    # Create or get dataset in Opik
    print('Creating dataset in Opik...')
    dataset_name = f"healthic-optimization-{datetime.now().strftime('%Y%m%d')}"
    dataset = opik_client.get_or_create_dataset(
        name=dataset_name,
        description="Health coach optimization scenarios"
    )

    # Insert items into dataset
    dataset.insert(OPTIMIZATION_DATASET)
    print(f'Dataset "{dataset_name}" ready with {len(OPTIMIZATION_DATASET)} items\n')

    # Create the prompt to optimize
    prompt = ChatPrompt(
        messages=[
            {"role": "system", "content": CURRENT_SYSTEM_PROMPT},
            {"role": "user", "content": "Context: {context}\n\n{input}"}
        ],
        model="gemini/gemini-2.0-flash",  # Use Gemini via LiteLLM
    )

    # Initialize optimizer
    print('Initializing MetaPromptOptimizer...')
    optimizer = MetaPromptOptimizer(
        model="gemini/gemini-2.0-flash",  # LiteLLM format for Gemini
        n_threads=2,
        seed=42,
    )

    # Create metric
    print('Creating evaluation metric...\n')
    metric = create_health_coach_metric()

    print('Starting optimization (this may take a few minutes)...\n')

    try:
        result = optimizer.optimize_prompt(
            prompt=prompt,
            dataset=dataset,
            metric=metric,
            max_trials=3,  # Start small
            project_name="healthic-optimization",
        )

        print('\n' + '=' * 60)
        print('‚úÖ OPTIMIZATION COMPLETE')
        print('=' * 60 + '\n')

        # Try to display results
        if hasattr(result, 'display'):
            result.display()

        # Save results
        output_dir = Path(__file__).parent.parent / 'docs'
        output_dir.mkdir(exist_ok=True)

        output_path = output_dir / 'optimization-results.md'
        with open(output_path, 'w') as f:
            f.write('# Prompt Optimization Results\n\n')
            f.write(f'Generated: {datetime.now().isoformat()}\n\n')
            f.write('## Original Prompt\n\n```\n')
            f.write(CURRENT_SYSTEM_PROMPT)
            f.write('\n```\n\n')

            if hasattr(result, 'best_prompt'):
                f.write('## Optimized Prompt\n\n```\n')
                f.write(str(result.best_prompt))
                f.write('\n```\n\n')

            if hasattr(result, 'history'):
                f.write('## Optimization History\n\n')
                for i, trial in enumerate(result.history):
                    f.write(f'### Trial {i+1}\n')
                    f.write(f'Score: {trial.get("score", "N/A")}\n\n')

        print(f'üìù Results saved to: {output_path}')
        print('\nüîó View in Opik dashboard: https://www.comet.com/opik')

        return result

    except Exception as e:
        print(f'\n‚ùå Error: {e}')
        import traceback
        traceback.print_exc()
        return None


def run_baseline():
    """Run baseline evaluation and log to Opik."""
    print('üìè Running Baseline Evaluation')
    print('=' * 60 + '\n')

    import google.generativeai as genai
    genai.configure(api_key=os.getenv('GOOGLE_GENAI_API_KEY'))
    model = genai.GenerativeModel('gemini-2.0-flash')

    metric = create_health_coach_metric()
    scores = []
    experiment_id = f"baseline-{datetime.now().strftime('%Y%m%d-%H%M%S')}"

    for i, item in enumerate(OPTIMIZATION_DATASET):
        print(f'Scenario {i+1}/{len(OPTIMIZATION_DATASET)}: {item["input"][:40]}...')

        # Generate response
        full_prompt = f"{CURRENT_SYSTEM_PROMPT}\n\nContext: {item.get('context', 'None')}\n\nUser: {item['input']}"

        try:
            response = model.generate_content(full_prompt)
            llm_output = response.text

            # Evaluate
            score = metric(item, llm_output)
            scores.append(score)

            # Log to Opik
            trace = opik_client.trace(
                name='baseline_evaluation',
                input={
                    'user_message': item['input'],
                    'context': item.get('context', ''),
                    'expected': item.get('expected', '')
                },
                metadata={
                    'experiment_id': experiment_id,
                    'scenario_index': i,
                    'evaluation_type': 'baseline'
                }
            )
            trace.update(
                output={'response': llm_output[:500], 'score': score},
                metadata={'score': score}
            )
            trace.end()

            print(f'  Score: {score:.2f}')

        except Exception as e:
            print(f'  Error: {e}')
            scores.append(0)

    # Flush traces to Opik
    opik_client.flush()

    avg_score = sum(scores) / len(scores) if scores else 0
    print('\n' + '=' * 60)
    print(f'üìä Baseline Average Score: {avg_score:.2f}')
    print(f'   Min: {min(scores):.2f}, Max: {max(scores):.2f}')
    print(f'\nüîó View traces in Opik: https://www.comet.com/opik')
    print('=' * 60)

    return scores


if __name__ == '__main__':
    if '--baseline' in sys.argv:
        run_baseline()
    else:
        run_optimization()
